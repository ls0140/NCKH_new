# ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh PhÃ¡t Hiá»‡n Tin Giáº£

ThÆ° má»¥c nÃ y chá»©a cÃ¡c script Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh phÃ¡t hiá»‡n tin giáº£ sá»­ dá»¥ng cÃ¡c metrics chuáº©n.

## ğŸ“Š CÃ¡c Metrics ÄÃ¡nh GiÃ¡

Viá»‡c Ä‘Ã¡nh giÃ¡ sá»­ dá»¥ng 4 metrics chÃ­nh:

1. **Precision**: Äo Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c dá»± Ä‘oÃ¡n dÆ°Æ¡ng tÃ­nh
2. **F1-Score**: Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a precision vÃ  recall
3. **RMSE**: Root Mean Square Error (cÃ ng tháº¥p cÃ ng tá»‘t)
4. **Accuracy**: Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng tá»•ng thá»ƒ

## ğŸš€ CÃ¡c Script CÃ³ Sáºµn

### 1. `clean_evaluate.py` (Khuyáº¿n nghá»‹)
- **Code sáº¡ch, cÃ³ tá»• chá»©c** vá»›i xá»­ lÃ½ lá»—i tá»‘t
- **Visualization chuyÃªn nghiá»‡p** vá»›i matplotlib
- **Há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ cuá»‘i cÃ¹ng** vá»›i xáº¿p loáº¡i (A+, A, B, C, D)
- **Mock predictions** Ä‘á»ƒ test nhanh

### 2. `real_model_evaluate.py`
- **TÃ­ch há»£p AI model tháº­t** (khi sáºµn sÃ ng)
- Sá»­ dá»¥ng model Vietnamese LLaMA tháº­t
- PhÃ¢n tÃ­ch RAG-based vá»›i knowledge base

## ğŸ¯ CÃ¡ch Sá»­ Dá»¥ng

### Test Nhanh (Mock Model)
```bash
python clean_evaluate.py
```

### Vá»›i AI Model Tháº­t
```bash
# Chá»‰nh sá»­a real_model_evaluate.py vÃ  set use_real_model=True
python real_model_evaluate.py
```

## ğŸ“ˆ Káº¿t Quáº£ Äáº§u Ra

Viá»‡c Ä‘Ã¡nh giÃ¡ cung cáº¥p:

1. **Káº¿t quáº£ Console**: Metrics chi tiáº¿t vÃ  confusion matrix
2. **ÄÃ¡nh giÃ¡ cuá»‘i cÃ¹ng**: Xáº¿p loáº¡i vÃ  khuyáº¿n nghá»‹
3. **Visualization**: Dashboard 4 panel vá»›i:
   - Biá»ƒu Ä‘á»“ cá»™t cÃ¡c metrics hiá»‡u suáº¥t
   - Heatmap confusion matrix
   - Visualization RMSE
   - TÃ³m táº¯t hiá»‡u suáº¥t

## ğŸ† Há»‡ Thá»‘ng ÄÃ¡nh GiÃ¡

| Äiá»ƒm | Xáº¿p Loáº¡i | ÄÃ¡nh GiÃ¡ | Khuyáº¿n Nghá»‹ |
|------|----------|----------|-------------|
| â‰¥0.8 | A+ | XUáº¤T Sáº®C | Sáºµn sÃ ng cho production |
| â‰¥0.7 | A | Tá»T | CÃ³ thá»ƒ cáº£i thiá»‡n nhá» |
| â‰¥0.6 | B | CHáº¤P NHáº¬N ÄÆ¯á»¢C | Cáº§n cáº£i thiá»‡n trÆ°á»›c khi deploy |
| â‰¥0.5 | C | Cáº¦N Cáº¢I THIá»†N | Cáº§n cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ |
| <0.5 | D | KÃ‰M | Cáº§n overhaul hoÃ n toÃ n |

## ğŸ”§ TÃ¹y Chá»‰nh

### Thay Äá»•i KÃ­ch ThÆ°á»›c Máº«u
```python
# Trong clean_evaluate.py
evaluator.evaluate(sample_size=50)  # Test trÃªn 50 máº«u
```

### Sá»­ Dá»¥ng Model Tháº­t
```python
# Trong real_model_evaluate.py
results, verdict = evaluate_model(use_real_model=True, sample_size=20)
```

### ThÃªm Metrics TÃ¹y Chá»‰nh
```python
# ThÃªm metrics cá»§a báº¡n trong calculate_metrics() method
metrics['custom_metric'] = your_calculation()
```

## ğŸ“ CÃ¡c File

- `clean_evaluate.py` - Script Ä‘Ã¡nh giÃ¡ chÃ­nh
- `real_model_evaluate.py` - PhiÃªn báº£n AI model tháº­t
- `evaluation_results.png` - Visualization Ä‘Æ°á»£c táº¡o
- `llm_training_complete.csv` - Dataset test

## ğŸ‰ VÃ­ Dá»¥ Káº¿t Quáº£

```
ğŸ¯ Precision:    0.8100
âš¡ F1-Score:     0.8526
ğŸ“ˆ Accuracy:     0.9000
ğŸ“ RMSE:         0.8434

ğŸ‘ ÄÃNH GIÃ CUá»I CÃ™NG: Tá»T (A)
ğŸ’¡ Khuyáº¿n nghá»‹: MÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t, cÃ³ thá»ƒ cáº£i thiá»‡n nhá»
```

## ğŸš¨ Xá»­ LÃ½ Sá»± Cá»‘

### Thiáº¿u Dependencies
```bash
pip install pandas numpy scikit-learn matplotlib
```

### Váº¥n Äá» Dataset
- Script tá»± Ä‘á»™ng táº¡o dá»¯ liá»‡u giáº£ náº¿u khÃ´ng tÃ¬m tháº¥y dataset
- Äáº£m báº£o `llm_training_complete.csv` cÃ³ cá»™t 'content' vÃ  'label'

### Váº¥n Äá» Bá»™ Nhá»›
- Giáº£m sample_size cho dataset lá»›n
- Sá»­ dá»¥ng mock predictions Ä‘á»ƒ test nhanh

## ğŸ“ Há»— Trá»£

Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» hoáº·c cÃ¢u há»i vá» cÃ¡c script Ä‘Ã¡nh giÃ¡, kiá»ƒm tra:
1. TÆ°Æ¡ng thÃ­ch phiÃªn báº£n Python
2. Dependencies cáº§n thiáº¿t
3. Äá»‹nh dáº¡ng dataset
4. Giá»›i háº¡n bá»™ nhá»› cho Ä‘Ã¡nh giÃ¡ model tháº­t

## ğŸ’¡ LÆ°u Ã

- Script nÃ y Ä‘Æ°á»£c viáº¿t Ä‘á»ƒ dá»… sá»­ dá»¥ng vÃ  má»Ÿ rá»™ng
- CÃ³ thá»ƒ tÃ¹y chá»‰nh theo nhu cáº§u cá»¥ thá»ƒ cá»§a dá»± Ã¡n
- NÃªn test vá»›i mock trÆ°á»›c khi cháº¡y model tháº­t
- Káº¿t quáº£ Ä‘Æ°á»£c lÆ°u dÆ°á»›i dáº¡ng hÃ¬nh áº£nh Ä‘á»ƒ dá»… chia sáº» 